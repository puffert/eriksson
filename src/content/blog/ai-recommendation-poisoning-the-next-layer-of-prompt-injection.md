---
title: "AI Recommendation Poisoning: The Next Layer of Prompt Injection"
description: "AI Recommendation Poisoning targets persistent memory features in AI assistants.  Attackers embed hidden instructions in AI-triggering links (e.g., “Summarize with AI” buttons).  These instructions may be stored as long-term memory.  Future AI recommendations become biased without user awareness.  This expands the AI attack surface beyond single-session prompt injection into cross-session behavioral manipulation."
pubDate: 2026-02-21
category: "News"
tags: ["_No response_"]
image: "news.png"
draft: false
---

Based on research published by Microsoft Security (February 2026).


---

TL;DR

AI Recommendation Poisoning targets persistent memory features in AI assistants.

Attackers embed hidden instructions in AI-triggering links (e.g., “Summarize with AI” buttons).

These instructions may be stored as long-term memory.

Future AI recommendations become biased without user awareness.

This expands the AI attack surface beyond single-session prompt injection into cross-session behavioral manipulation.



---

From Prompt Injection to Memory Manipulation

We are already familiar with:

Prompt injection

Indirect prompt attacks

RAG poisoning

Tool abuse

---

[Original Source](https://www.microsoft.com/en-us/security/blog/2026/02/10/ai-recommendation-poisoning/)